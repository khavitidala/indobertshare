{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a54de4ff-777b-4082-b07c-518d6216f8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00b6314e-7ff5-4ea6-a583-536d0b42c48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [f for f in glob.glob(\"results/*.json\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b52e71a-68a1-4c83-aeb8-010e6ebea9c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "436779"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b110e15-2089-449d-af8f-7b652a2b8a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'results/2000461.json'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1feb2fd3-7870-4ccc-9967-c516aced068f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0864ef55ec6c4fd083374c2b9e06981d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/436779 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-c572ac2f0a053e71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/.cache/huggingface/datasets/json/default-c572ac2f0a053e71/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1a4ffd9438043ee9602335d1ba78199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e570b8da39024aecafd39cc5eb73089b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/.cache/huggingface/datasets/json/default-c572ac2f0a053e71/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be52183258464d30b6866ebff4f74172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = datasets.load_dataset(path=\"json\", data_files=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a44469cc-c141-4cfa-8c84-d917e586bbce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'url', 'title', 'date', 'content', 'summary'],\n",
       "        num_rows: 436779\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dcd8a2a7-d21c-4c00-96d4-8b93d46aec7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re, os\n",
    "\n",
    "regex_bracket = r\"\\(([^)]+)\\)\"\n",
    "punctuation = '.,!?\\'\\[]();\"'\n",
    "unknown = set()\n",
    "\n",
    "def cleanhtml(raw_html):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', raw_html)\n",
    "    return cleantext\n",
    "\n",
    "def clean_article(article):\n",
    "    article = cleanhtml(article)\n",
    "    article = article.replace('\\n', ' ')\n",
    "    sentences = []\n",
    "    words = []\n",
    "    for word in article.split(' '):\n",
    "        word = word.replace('–', '-')\n",
    "        word = word.replace('__', '').replace('--', '')\n",
    "        word = word.replace('&quot', '\"')\n",
    "        word = word.strip()\n",
    "        if len(word) > 0:\n",
    "            tokens = re.findall(r\"[\\w'\\%\\&\\-\\/\\=\\+\\*$£]+|[\\[\\]().,!?\\:;\\\"\\“\\”]\", word)\n",
    "            words += tokens\n",
    "            try:\n",
    "                if tokens[-1] in '.!?':\n",
    "                    sentences.append(words)\n",
    "                    words = []\n",
    "            except:\n",
    "                unknown.add(word)\n",
    "    if words != []:\n",
    "        if not words[-1][-1] in '.!?':\n",
    "            words.append('.')\n",
    "        sentences.append(words)\n",
    "    return sentences\n",
    "\n",
    "def get_string(sentences):\n",
    "    all_sentence = []\n",
    "    for sentence in sentences:\n",
    "        all_sentence += sentence\n",
    "    return ' '.join(all_sentence)\n",
    "\n",
    "\n",
    "def process(batch):\n",
    "    for i in range(len(batch['content'])):\n",
    "        clean_data = {}\n",
    "        article = batch['content'][i]\n",
    "        summary = batch['summary'][i]\n",
    "        if(len(article.split())>30 and len(summary.split())>10):\n",
    "            article_arr = clean_article(article)\n",
    "            summary_arr = clean_article(summary)\n",
    "            clean_data['id'] = batch['id'][i]\n",
    "            clean_data['url'] = batch['url'][i]\n",
    "\n",
    "            article_v2 = get_string(article_arr).split()\n",
    "            summary_v2 = get_string(summary_arr).split()\n",
    "\n",
    "            if len(article_v2) < len(article.split()) or len(summary_v2) < len(summary.split()):\n",
    "                print(str(batch['id'][i]))\n",
    "\n",
    "            clean_data['clean_article'] = article_arr\n",
    "            clean_data['clean_summary'] = summary_arr\n",
    "            with open(\"liputan6_extend/\"+str(clean_data['id'])+'.json', 'w') as json_file:\n",
    "                json.dump(clean_data, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c099eeb6-5da1-4556-bb3c-102c99a0a2d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "619e8b90e19a449f90453f53c5fb9abe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13650 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016587\n",
      "2084039\n",
      "756737\n",
      "576305\n",
      "542849\n",
      "2668643\n",
      "2493496\n",
      "2139709\n",
      "2404262\n",
      "2345180\n",
      "2279227\n",
      "2143619\n",
      "2155070\n",
      "2176187\n",
      "2329590\n",
      "2331950\n",
      "2379166\n",
      "2984692\n",
      "711530\n"
     ]
    }
   ],
   "source": [
    "ds = dataset[\"train\"].map(\n",
    "    process,\n",
    "    batched=True,\n",
    "    batch_size=32,\n",
    "    remove_columns=['id', 'url', 'title', 'date', 'content', 'summary']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8320c56-5a36-4a24-bee8-447aba71b420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'url', 'title', 'date', 'content', 'summary'],\n",
       "    num_rows: 436779\n",
       "})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81b93a14-3ee5-4f9f-91cd-d65d1227370e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a8c95b219244af49412a6cdf3c90928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/367693 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-9307b48c1d9e3dc4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/.cache/huggingface/datasets/json/default-9307b48c1d9e3dc4/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8418721191a74b409712756df19c231b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7911b2a4a6c34d7c93bf8d7a9d492d01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/.cache/huggingface/datasets/json/default-9307b48c1d9e3dc4/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8faca1c125844cabaf847d5207c6b4dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = datasets.load_dataset(path=\"json\", data_files=[f for f in glob.glob(\"liputan6_extend/*.json\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b0df969-e71e-41a8-96ea-9f4c6ba974a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "367693"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([f for f in glob.glob(\"liputan6_extend/*.json\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "87a52cd3-4e75-4fb6-b454-3a5284ca4a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'url', 'clean_article', 'clean_summary'],\n",
       "        num_rows: 367693\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d24d5e3-86ac-4629-b33a-779e944dfea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gabung(batch):\n",
    "    return {\n",
    "        'id': batch[\"id\"],\n",
    "        'url': batch[\"url\"],\n",
    "        'clean_article': [get_string(s) for s in batch['clean_article']],\n",
    "        'clean_summary': [get_string(s) for s in batch['clean_summary']]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4aee4bc9-c732-499c-9d31-1a7705be975a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec42606c782d411db98859b82252368b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/719 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e63137babce41b695aecb8bd6edbf14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/719 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d08b44d9d604e3c904a52b9421a3a70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/719 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "122816b3aca84a46a3a2e56579a2efc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/719 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = dataset.map(\n",
    "    gabung,\n",
    "    batched=True,\n",
    "    batch_size=128,\n",
    "    remove_columns=['id', 'url', 'clean_article', 'clean_summary'],\n",
    "    num_proc=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4a191f41-73c7-49ca-ba9f-2f3e1cb7acdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'url', 'clean_article', 'clean_summary'],\n",
       "        num_rows: 367693\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "214d810c-4e15-4d9a-b9b1-c043febe2989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_article</th>\n",
       "      <th>clean_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Liputan6 . com , Jakarta - Kapolri Jendral Polisi Sutarman memerintahkan seluruh jajarannya agar mengawal dan mengamankan setiap tahapan Pemilu 2014 dengan baik . Sebab , setiap tahapan pemilu berpotensi menimbulkan kerawanan . Amanat itu disampaikan Sutarman saat apel operasi Mantap Brata 2014 untuk Pengamanan Pemilu di Lapangan Monumen Nasional , Jakarta , Kamis ( 30/1/2014 ) Ia menekankan kepada jajarannya untuk menjaga situasi kemanan kondusif serta memberikan rasa aman kepada peserta dan penyelenggara pemilu . \" Harus menjamin masyarakat menggunakan hak pilihnya dengan jernih sesuai hati nurani , \" imbau Sutarman . Selain itu , adanya intimidasi dari kelompok-kelompok tertentu yang kemungkinan terjadi di setiap wilayah saat pemilu juga harus dihentikan . Potensi tersebut merupakan tindak pidana pemilu . \" Terkait tindak pidana pemilu , kita bekerja sama dengan kejaksaan dan Bawaslu . Peran Gakkumdu juga akan dioptimalkan untuk menyelesaikan tuntas pelanggaran pemilu di seluruh tahapan , \" papar dia . Setiap pelanggaran yang dilaporkan masyarakat akan dinilai Kejaksaan , Sentra Gakkumdu , dan Polri . Sehingga polisi bisa menilai apakah pelangaran itu bentuknya bersifat administrasi , kode etik , atau tindak pidana . \" Setelah itu ditindaklanjuti sesuai pelanggaran yang terjadi , \" ungkap mantan Kabagreskrim itu . Ia menambahkan , saat ini logistik pemilu telah disiapkan . Semua pengamanan logistik merupakan tanggungjawab Polri . Mulai pendistribusian hingga ke TPS sampai kembalinya surat suara ke Kelompok Penyelenggara Pemungutan Suara . \" Karena itu perlu bersatu padu bersinergi dengan aparatur yang terlibat pengamanan pemilu . Sehingga dapat berjalan lancar aman jujur dan adil , \" tegas Sutarman . Karenanya , Sutarman meminta jajarannya terus melakukan latihan pengamanan di TPS , pengawalan logistik pemilu , pengamanan gedung-gedung penyelenggara pemilu yang bisa menjadi sasaran pelaku-pelaku untuk mengagalkan pemilu . \" Tingkatkan hingga latihan kontigensi , sehingga seluruh personel siap hadapi kontigensi , \" tukas Sutarman .</td>\n",
       "      <td>Kapolri Jendral Polisi Sutarman memerintahkan seluruh jajarannya agar mengawal dan mengamankan setiap tahapan Pemilu 2014 dengan baik .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "from datasets import ClassLabel\n",
    "\n",
    "df = pd.DataFrame(ds[\"train\"][:1])\n",
    "del df[\"id\"]\n",
    "del df[\"url\"]\n",
    "for column, typ in ds[\"train\"].features.items():\n",
    "    if isinstance(typ, ClassLabel):\n",
    "        df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "63b31f3c-8add-4f69-9fed-b4fa0d2b22f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import datasets\n",
    "import statistics\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "from functools import cached_property\n",
    "from transformers import BertTokenizer, Seq2SeqTrainingArguments, Seq2SeqTrainer, EncoderDecoderModel\n",
    "from config import *\n",
    "\n",
    "class AbsSumExtract:\n",
    "    \n",
    "    @cached_property\n",
    "    def tokenizer(self):\n",
    "        tokenizer = BertTokenizer.from_pretrained(extract_model_checkpoint)\n",
    "        tokenizer.bos_token = tokenizer.cls_token\n",
    "        tokenizer.eos_token = tokenizer.sep_token\n",
    "        return tokenizer\n",
    "\n",
    "    @cached_property\n",
    "    def extract_data(self):\n",
    "        return ds[\"train\"]\n",
    "    \n",
    "    @cached_property\n",
    "    def model(self):\n",
    "        model = EncoderDecoderModel.from_pretrained(extract_model_checkpoint)\n",
    "        model.to(\"cuda:0\")\n",
    "        return model\n",
    "    \n",
    "    def generate_summary(self, batch):\n",
    "        res_dict: dict = {\n",
    "            \"id\": [],\n",
    "            \"summary\": [],\n",
    "            \"generated_summary\": []\n",
    "        }\n",
    "        inputs = self.tokenizer(batch[\"clean_article\"], padding=\"max_length\", truncation=True, max_length=encoder_max_length, return_tensors=\"pt\")\n",
    "        input_ids = inputs.input_ids.to(\"cuda:0\")\n",
    "        attention_mask = inputs.attention_mask.to(\"cuda:0\")\n",
    "        outputs = self.model.generate(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            min_length=20,\n",
    "            max_length=80, \n",
    "            num_beams=4,\n",
    "            early_stopping=True,\n",
    "            no_repeat_ngram_size=3,\n",
    "        )\n",
    "        output_str = self.tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "        res_dict[\"id\"] += batch[\"id\"]\n",
    "        res_dict[\"summary\"] += batch[\"clean_summary\"]\n",
    "        res_dict[\"generated_summary\"] += output_str\n",
    "        \n",
    "        last_id = res_dict[\"id\"][-1]\n",
    "        name = extract_model_checkpoint.split('/')[-1]\n",
    "        fname = f\"{extract_path}{name}-{last_id}-from_scrap-extraction_results.csv\"\n",
    "        \n",
    "        df = pd.DataFrame(res_dict)\n",
    "        df.to_csv(fname, index=False)\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def extract(self):\n",
    "        _ = self.extract_data.map(\n",
    "            self.generate_summary,\n",
    "            batched=True,\n",
    "            batch_size=extract_batch_size,\n",
    "            remove_columns=[\"clean_article\", \"id\"]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "59f5fef0-d748-4b4d-8aa4-22570e6a1cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractcls = AbsSumExtract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f63e27c-525c-43c5-92aa-ec6fde766a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eaae041f21944b58bc023ee10ce6808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11491 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "extractcls.extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bee4a5-5a3d-4e4d-97b9-7e28f8b24f56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
