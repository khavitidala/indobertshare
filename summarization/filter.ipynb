{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install evaluate==0.3.0 rouge-score==0.1.2 sacrebleu==2.3.1 bert-score==0.3.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import torch\n",
    "import datasets\n",
    "import evaluate\n",
    "import statistics\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "from functools import cached_property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILTER_DATA_FOLDER = \"/workspace/indobertshare-main/summarization\"\n",
    "CODE_NAME = \"paracotta_full\"\n",
    "\n",
    "# Filtration Config\n",
    "filter_data_from_csv = False\n",
    "filter_data_path = \"paracotta_full.csv\"\n",
    "filter_data_conf: dict = {\n",
    "    \"path\": \"indonli\",\n",
    "    \"split\": \"train\",\n",
    "}\n",
    "filter_num_layer = 9\n",
    "filter_batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# df = pd.read_csv(\"generated-par.full.id\", delimiter=\"\\t\", names=[\"score\", \"references\", \"paraphrase\"], usecols = [\"references\", \"paraphrase\"], error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"paracotta_full.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset indonli (/root/.cache/huggingface/datasets/indonli/indonli/1.1.0/d34041bd1d1a555a4bcb4ffdb9fe904778da6f7c5343209fc1485dd68121cb62)\n"
     ]
    }
   ],
   "source": [
    "if filter_data_from_csv:\n",
    "    df = pd.read_csv(filter_data_path)\n",
    "    extract_data = datasets.Dataset.from_pandas(df)\n",
    "else:\n",
    "    extract_data = datasets.load_dataset(**filter_data_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>references</th>\n",
       "      <th>paraphrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Burton tidak pernah bersabar kecuali ketika it...</td>\n",
       "      <td>Burton tidak pernah sabar kecuali bila itu ben...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anna tahu kalau Kolom Kelima semakin kuat.</td>\n",
       "      <td>Anna tahu bahwa kelima kolom semakin kuat.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hanya saja, dia benar-benar meminta kita ... t...</td>\n",
       "      <td>Hanya saja, ia benar-benar meminta kami ... ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tak ada yang seperti meninggalkan rumah sakit ...</td>\n",
       "      <td>Tidak ada yang cukup mirip meninggalkan rumah ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Leibniz berhenti dan mempertimbangkan masalah ...</td>\n",
       "      <td>Leibniz berhenti dan memikirkan hal-hal.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          references  \\\n",
       "0  Burton tidak pernah bersabar kecuali ketika it...   \n",
       "1         Anna tahu kalau Kolom Kelima semakin kuat.   \n",
       "2  Hanya saja, dia benar-benar meminta kita ... t...   \n",
       "3  Tak ada yang seperti meninggalkan rumah sakit ...   \n",
       "4  Leibniz berhenti dan mempertimbangkan masalah ...   \n",
       "\n",
       "                                          paraphrase  \n",
       "0  Burton tidak pernah sabar kecuali bila itu ben...  \n",
       "1         Anna tahu bahwa kelima kolom semakin kuat.  \n",
       "2  Hanya saja, ia benar-benar meminta kami ... ti...  \n",
       "3  Tidak ada yang cukup mirip meninggalkan rumah ...  \n",
       "4           Leibniz berhenti dan memikirkan hal-hal.  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5959558"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_data2 = extract_data.select(range(filter_batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['premise', 'hypothesis', 'label'],\n",
       "    num_rows: 32\n",
       "})"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FilterDS():\n",
    "    def __init__(self, col1='references', col2='paraphrase'):\n",
    "        self.col1 = col1\n",
    "        self.col2 = col2\n",
    "        self.res = {\n",
    "                col1: [],\n",
    "                col2: [],\n",
    "                \"bert_score\": []\n",
    "            }\n",
    "    \n",
    "    @cached_property\n",
    "    def bertscore(self):\n",
    "        return evaluate.load(\"bertscore\")\n",
    "    \n",
    "    @cached_property\n",
    "    def sacrebleu(self):\n",
    "        return evaluate.load(\"sacrebleu\")\n",
    "    \n",
    "    def calculate_bertscore(self, batch):\n",
    "#         results = self.bertscore.compute(\n",
    "#             predictions=batch[self.col1],\n",
    "#             references=batch[self.col2],\n",
    "#             verbose=True,\n",
    "#             device=\"cuda:0\",\n",
    "#             lang=\"id\",\n",
    "#             model_type=\"bert-base-multilingual-cased\",\n",
    "#             num_layers=9,\n",
    "#             use_fast_tokenizer=False\n",
    "#         )\n",
    "        self.res[self.col1] += batch[self.col1]\n",
    "        self.res[self.col2] += batch[self.col2]\n",
    "        self.res[\"bert_score\"] += [0 for _ in range(len(batch[self.col1]))] #results[\"f1\"]\n",
    "\n",
    "        return None\n",
    "    \n",
    "    def calculate_ibleu(self, text):\n",
    "        res = self.sacrebleu.compute(predictions=[text[self.col1]], references=[text[self.col2]])\n",
    "        self.res[\"ibleu_score\"].append(100 - res[\"score\"])\n",
    "\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "fltr = FilterDS('premise', 'hypothesis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "torch.cuda.empty_cache()\n",
    "# phase I.1: calculate BERTScore for all data\n",
    "_ = extract_data2.map(\n",
    "    fltr.calculate_bertscore,\n",
    "    batched=True,\n",
    "    batch_size=filter_batch_size,\n",
    "    remove_columns=[fltr.col1, fltr.col2],\n",
    ")\n",
    "fname = f\"{CODE_NAME}-{str(int(datetime.now().timestamp()))}\"\n",
    "dfs = pd.DataFrame(fltr.res)\n",
    "# dfs.to_csv(f\"{fname}-phase1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# phase I.2: get average BERTScore from all data\n",
    "avg_bertscore = statistics.mean(fltr.res[\"bert_score\"])\n",
    "print(avg_bertscore)\n",
    "# with open(f\"{fname}-avg_bertscore.txt\", \"w\") as f:\n",
    "#     f.write(str(avg_bertscore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# phase I.3: filter data by score > average BERTScore\n",
    "extract_data2 = datasets.Dataset.from_pandas(dfs)\n",
    "extract_data2 = extract_data2.filter(lambda x: x[\"bert_score\"] >= avg_bertscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# phase II.1: calculate inverse BLEU for all data\n",
    "fltr.res[\"ibleu_score\"] = []\n",
    "_ = extract_data2.map(fltr.calculate_ibleu, batched=False, remove_columns=[fltr.col1, fltr.col2])\n",
    "dfs = pd.DataFrame(fltr.res)\n",
    "dfs.to_csv(f\"{fname}-phase2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.69773719258346\n"
     ]
    }
   ],
   "source": [
    "# phase II.2: get average inverse BLEU from all data\n",
    "avg_ibleu = statistics.mean(fltr.res[\"ibleu_score\"])\n",
    "print(avg_ibleu)\n",
    "# with open(f\"{fname}-avg_ibleu.txt\", \"w\") as f:\n",
    "#     f.write(str(avg_ibleu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# phase III.3: filter data by score > average inverse BLEU\n",
    "extract_data2 = datasets.Dataset.from_pandas(dfs)\n",
    "extract_data2 = extract_data2.filter(lambda x: x[\"ibleu_score\"] > avg_ibleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# save the final result\n",
    "# extract_data.save_to_disk(f\"./{fname}\")\n",
    "extract_data2.to_csv(f\"{fname}-final_result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ed5e7493260295f9550ef64ef791f3153fbb4139b19d37a3c7ca42906fdaa488"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
